# ğŸ™ï¸ SeamlessM4T Turkish Audio Demo

This miniâ€‘repository shows a **quick proofâ€‘ofâ€‘concept** for:

1. âœ‚ï¸ **Dataset slicing** â€“ grabbing 5â€‘second snippets from the Turkish split of the CommonÂ VoiceÂ 12.0 corpus.  
2. ğŸŒ **SeamlessM4TÂ v2â€‘large** â€“ loading MetaÂ AIâ€™s multilingual speech model and running it on GPU.  
3. ğŸ”Š **Audio generation** â€“ producing English speech from Turkish input.

---

## ğŸ—‚ï¸ Repository Contents

| File | Purpose |
|------|---------|
| `dataset_loader.py` | Downloads CommonÂ VoiceÂ 12Â (TR), converts the first sample to WAV, crops first 5â€¯s â†’ `snippet.wav`. |
| `seamless_try.ipynb` | Jupyter notebook: loads `facebook/seamless-m4t-v2-large`, translates *snippet* (or any WAV) to English audio & text. |
| `generated_audio_eng.wav` | Example output audio generated by the notebook. |
| `tr_dataset_sample.wav` | Example Turkish clip (original). |
| `README.md` | Youâ€™re reading it. |

---

## âš™ï¸ Quick Start

### 1. Clone & enter

```bash
git clone https://github.com/yourâ€‘username/seamlessm4t-demo.git
cd seamlessm4t-demo
```

### 2. Install requirements

> Requires **PythonÂ 3.10+** and a recent GPUâ€‘enabled PyTorch.

```bash
pip install transformers datasets pydub torchaudio ipywidgets
# FFmpeg is also needed for pydub:
# Ubuntu: sudo apt-get install ffmpeg
```

### 3. Run the dataset loader

```bash
python dataset_loader.py
# â†’ creates snippet.wav (5â€‘second Turkish sample)
```

### 4. Open the notebook

```bash
jupyter notebook seamless_try.ipynb
```

Inside the notebook you will:

1. Load **SeamlessM4T v2â€‘large**.  
2. Send `snippet.wav`.  
3. Get English transcription **and** generated speech (saved as `generated_audio_eng.wav`).

---

## ğŸ’¡ Notes

* Notebook automatically moves the model to **CUDA** if available (`model.to("cuda")`).  
* Cropped snippets keep sampling rate & channels intact for best quality.  
* For largeâ€‘scale use, iterate over the dataset in `dataset_loader.py` and feed batches into SeamlessM4T.

---

## ğŸ“œ License

Code is MIT; audio samples come from **Mozilla CommonÂ Voice** (CCâ€‘BYâ€‘SAÂ 4.0).

---

## ğŸ™ Acknowledgements

- MetaÂ AI â€“ *SeamlessM4T*  
- Mozilla â€“ *Common Voice*  
- HuggingFace â€“ *transformers* / *datasets*
